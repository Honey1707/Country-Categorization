# -*- coding: utf-8 -*-
"""Minor Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S7SddaRQRhlHBHo1WuchP-V_V-cQRqtO

# ***Preprocessing and EDA***
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler,StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn import metrics
import scipy.cluster.hierarchy as shc
from sklearn.neighbors import NearestNeighbors
from sklearn.cluster import DBSCAN
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score

data = pd.read_csv("/content/Country-data.csv")

data

data.columns

data.shape

data.describe()

data.info()

data.isnull().sum()

col = list(data.columns)
col.remove('country')

categorical_features = ['country']
numerical_features = col
print('Categorical Features :',*categorical_features)
print('Numerical Features :',*numerical_features)

# Distribution Plots
fig, ax = plt.subplots(nrows = 3,ncols = 3,figsize = (15,15))
for i in range(len(numerical_features)):
    plt.subplot(3,3,i+1)
    sns.distplot(data[numerical_features[i]])
    title = 'Distribution : ' + numerical_features[i]
    plt.title(title)
plt.show()

fig  = plt.subplots(nrows = 3,ncols = 3,figsize = (15,15))
for i in range(len(numerical_features)):
    plt.subplot(3,3,i+1)
    ax = sns.boxplot(data[numerical_features[i]])
    plt.title(numerical_features[i])
plt.show()

# Correlation Map Of Country Data  
plt.figure(figsize=(10, 5))
corr_matrix=data.corr()
sns.heatmap(corr_matrix,annot=True)

# Data Scaling
# Normalization
mms = MinMaxScaler() 
# Standardization
ss = StandardScaler()

# Categories of the features
df = pd.DataFrame()
df['Health'] = (data['child_mort'] / data['child_mort'].mean()) + (data['health'] / data['health'].mean()) + (data['life_expec'] / data['life_expec'].mean()) + (data['total_fer'] / data['total_fer'].mean())
df['Trade'] = (data['imports'] / data['imports'].mean()) + (data['exports'] / data['exports'].mean())
df['Finance'] = (data['income'] / data['income'].mean()) + (data['inflation'] / data['inflation'].mean()) + (data['gdpp'] / data['gdpp'].mean())

df['Health'] = mms.fit_transform(df[['Health']])
df['Trade'] = mms.fit_transform(df[['Trade']])
df['Finance'] = mms.fit_transform(df[['Finance']])
df.insert(loc = 0, value = list(data['country']), column = 'Country')
df.head()

"""# ***PCA***"""

# Principal Component Analysis
pca_df = data.copy(deep = True)

col = list(data.columns)
col.remove('health'); col.remove('country')

pca_df['health'] = ss.fit_transform(pca_df[['health']])

for i in col:
    pca_df[i] = mms.fit_transform(pca_df[[i]])
pca_df.drop(columns = 'country',inplace = True) 
pca_df.head()

pca = PCA()
pca_df = pd.DataFrame(pca.fit_transform(pca_df))

# plot of Cumulative Summation of the Explained Variance
plt.figure()
plt.plot(np.cumsum(pca.explained_variance_ratio_),marker='o')

plt.xlabel('Number of Components')
plt.ylabel('Ratio of Variance Explained') 
plt.title('Explained Variance')

plt.show()

pca_df = pca_df.drop(columns = [3,4,5,6,7,8])
pca_df.head()

"""# ***KMeans***

***Normal data***
"""

# K-Means Clustering
kmeans_df = df.drop(columns = ['Country'])

model = []
K = range(1,10)
for k in K:
    km = KMeans(n_clusters=k)
    km.fit(kmeans_df)
    model.append(km.inertia_)

# Elbow curve
fig = plt.subplots(nrows = 1, ncols = 2, figsize = (20,5))

plt.subplot(1,2,1)
plt.plot(K, model, 'bx-')
plt.xlabel('k')
plt.ylabel('sum of squared distances')
plt.title('Elbow Method For Optimal k')

# Silhouette Score
k_range = range(2, 10)
scores = []

for k in k_range:
    km = KMeans(n_clusters=k, random_state=0).fit(kmeans_df)
    scores.append(metrics.silhouette_score(kmeans_df, km.labels_))

plt.subplot(1,2,2)
plt.plot(k_range, scores, 'bx-')
plt.xlabel('k')
plt.ylabel('Silhouette Scores')
plt.title('Silhoutte score method')
plt.show()

km = KMeans(n_clusters=3, init='random',n_init=10, max_iter=1000,tol=1e-04, random_state=0)
km.fit(kmeans_df)

# Cluster labels and centroids
labels = km.labels_
centroids = km.cluster_centers_
kmeans_df_array = kmeans_df.values

# Ploting data points 
plt.scatter(kmeans_df_array[:, 0], kmeans_df_array[:, 1], c=labels)

# Ploting centroids 
plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=70, linewidths=3, color='r')
plt.show()

print(metrics.silhouette_score(kmeans_df, labels))

data['Class'] = labels
kmeans_df['Class'] = labels

# Bar plot 
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))

plt.subplot(1,2,1)
sns.barplot(x = 'Class', y = 'child_mort', data  = data);
plt.title('child_mort vs Class')

plt.subplot(1,2,2)
sns.barplot(x = 'Class', y = 'income', data  = data);
plt.title('income vs Class')

plt.show()

kmeans_df.insert(0,column = 'Country', value = data['country'])

kmeans_df['Class'] = kmeans_df['Class'].replace({0: 'No', 1: 'Yes', 2: 'Might'})
kmeans_df.head()

"""***PCA Data***"""

model = []
K = range(1,10)
for k in K:
    km = KMeans(n_clusters=k)
    km.fit(pca_df)
    model.append(km.inertia_)

# Elbow curve
fig = plt.subplots(nrows = 1, ncols = 2, figsize = (20,5))

plt.subplot(1,2,1)
plt.plot(K, model, 'bx-')
plt.xlabel('k')
plt.ylabel('sum of squared distances')
plt.title('Elbow Method For Optimal k')

# Silhouette Score
k_range = range(2, 10)
scores = []

for k in k_range:
    km = KMeans(n_clusters=k, random_state=0).fit(pca_df)
    scores.append(metrics.silhouette_score(pca_df, km.labels_))

plt.subplot(1,2,2)
plt.plot(k_range, scores, 'bx-')
plt.xlabel('k')
plt.ylabel('Silhouette Scores')
plt.title('Silhoutte score method')
plt.show()

km = KMeans(n_clusters=3, init='random',n_init=10, max_iter=1000,tol=1e-04, random_state=0)
km.fit(pca_df)

# Cluster labels and centroids
labels = km.labels_
centroids = km.cluster_centers_
pca_df_array = pca_df.values

# Ploting data points 
plt.scatter(pca_df_array[:, 0], pca_df_array[:, 1], c=labels)

# Ploting centroids 
plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=70, linewidths=3, color='r')
plt.show()

print(metrics.silhouette_score(pca_df, labels))

data = data.drop(columns = ['Class'])
data['Class'] = labels
pca_df['Class'] = labels

# Bar plot
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))

plt.subplot(1,2,1)
sns.barplot(x = 'Class', y = 'child_mort', data  = data);
plt.title('child_mort vs Class')

plt.subplot(1,2,2)
sns.barplot(x = 'Class', y = 'income', data  = data);
plt.title('income vs Class')

plt.show()

pca_df.insert(0,column = 'Country', value = data['country'])

pca_df['Class'] = pca_df['Class'].replace({0: 'Yes', 1: 'Might', 2: 'No'})
pca_df.head()

"""# ***Hierarchical Clustering***

***Normal data***
"""

hc_df = df.drop(columns = ['Country'])

plt.figure(figsize=(20, 8))
plt.title("Dendrogram")
dend = shc.dendrogram(shc.linkage(hc_df, method='ward'))

# Plot the dendrogram
plt.show()

hc = AgglomerativeClustering(n_clusters=3, affinity = 'euclidean', linkage = 'ward')
Y_hc = hc.fit_predict(hc_df)

hcpreds = hc.labels_
data_hc_df = hc_df
data_hc_df.head(10)

hc_df_array = data_hc_df.values

plt.scatter(hc_df_array[:, 0], hc_df_array[:, 1], c=hcpreds, cmap='viridis')
plt.show()

print(metrics.silhouette_score(data_hc_df, hcpreds))

data_hc_df['Hier_Clusters'] = hcpreds
data = data.drop(columns = ['Class'])
data['Hier_Clusters'] = hcpreds

# Bar plot 
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))

plt.subplot(1,2,1)
sns.barplot(x = 'Hier_Clusters', y = 'child_mort', data  = data);
plt.title('child_mort vs Class')

plt.subplot(1,2,2)
sns.barplot(x = 'Hier_Clusters', y = 'income', data  = data);
plt.title('income vs Class')

plt.show()

data_hc_df.insert(0,column = 'Country', value = data['country'])

data_hc_df['Hier_Clusters'] = data_hc_df['Hier_Clusters'].replace({0: 'No', 1: 'Yes', 2: 'Might'})
data_hc_df.head()

"""***PCA Data***"""

pca_df = pca_df.drop(columns = ['Country','Class'])

plt.figure(figsize=(20, 8))
plt.title("Dendrogram")
dend = shc.dendrogram(shc.linkage(pca_df, method='ward'))

# Plot the dendrogram
plt.show()

from sklearn.cluster import AgglomerativeClustering
hc = AgglomerativeClustering(n_clusters=3, affinity = 'euclidean', linkage = 'ward')
Y_hc = hc.fit_predict(pca_df)

hcpreds = hc.labels_
data_pca_df = pca_df
data_pca_df.head(10)

hc_df_array = data_pca_df.values

plt.scatter(hc_df_array[:, 0], hc_df_array[:, 1], c=hcpreds, cmap='viridis')
plt.show()

print(metrics.silhouette_score(data_pca_df, hcpreds))

data_pca_df['Hier_Clusters'] = hcpreds
data = data.drop(columns = ['Hier_Clusters'])
data['Hier_Clusters'] = hcpreds

# Bar plot 
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))

plt.subplot(1,2,1)
sns.barplot(x = 'Hier_Clusters', y = 'child_mort', data  = data);
plt.title('child_mort vs Class')

plt.subplot(1,2,2)
sns.barplot(x = 'Hier_Clusters', y = 'income', data  = data);
plt.title('income vs Class')

plt.show()

pca_df.insert(0,column = 'Country', value = data['country'])

pca_df['Hier_Clusters'] = pca_df['Hier_Clusters'].replace({0: 'Yes', 1: 'Might', 2: 'No'})
pca_df.head()

"""# ***DBSCAN***

***Normal Data***
"""

db_df = df.drop(columns = ['Country'])

# Computing the distance to the kth nearest neighbor
k = 5
neighbors = NearestNeighbors(n_neighbors=k)
neighbors_fit = neighbors.fit(db_df)
distances, indices = neighbors_fit.kneighbors(db_df)

# Sorting the distances in descending order
distances = np.sort(distances, axis=0)
distances = distances[:,1]

# Elbow curve
plt.plot(distances)
plt.xlabel('Points')
plt.ylabel('Distance to 5th nearest neighbor(k=5)')
plt.title('Elbow Curve')
plt.show()

dbscan = DBSCAN(eps=0.08, min_samples=5)
clusters = dbscan.fit_predict(db_df)

labels = dbscan.labels_

print("Cluster assignments:\n", labels)

plt.scatter(db_df.iloc[:,0], db_df.iloc[:,1], c=clusters)
plt.xlabel('GDP per capita')
plt.ylabel('Life expectancy')
plt.show()

predictions_db = pd.Series(labels)
predictions_db

unique_labels, counts = np.unique(labels, return_counts=True)
percentages = counts / len(labels) * 100

# value counts and percentages
print("Value counts:")
for i, label in enumerate(unique_labels):
    print(f"Class {label}: {counts[i]}")
print("")

print("Percentages:")
for i, label in enumerate(unique_labels):
    print(f"Class {label}: {percentages[i]:.2f}%")

print('Silhouette Score:', silhouette_score(db_df, predictions_db))

db_df['Class'] = predictions_db
data = data.drop(columns = ['Hier_Clusters'])
data['Class'] = predictions_db

# Bar plot
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))

plt.subplot(1,2,1)
sns.barplot(x = 'Class', y = 'child_mort', data  = data);
plt.title('child_mort vs Class')

plt.subplot(1,2,2)
sns.barplot(x = 'Class', y = 'income', data  = data);
plt.title('income vs Class')

plt.show()

db_df.insert(0,column = 'Country', value = data['country'])

db_df['Class'] = db_df['Class'].replace({-1: 'Noise', 0: 'Yes', 1: 'No'})
db_df.head()

"""***PCA Data***"""

pca_df = pca_df.drop(columns = ['Country','Hier_Clusters'])

# Computing the distance to the kth nearest neighbor
k = 5
neighbors = NearestNeighbors(n_neighbors=k)
neighbors_fit = neighbors.fit(pca_df)
distances, indices = neighbors_fit.kneighbors(pca_df)

# Sorting the distances in descending order
distances = np.sort(distances, axis=0)
distances = distances[:,1]

# Elbow curve
plt.plot(distances)
plt.xlabel('Points')
plt.ylabel('Distance to 5th nearest neighbor')
plt.title('Elbow Curve')
plt.show()

dbscan = DBSCAN(eps=0.2, min_samples=6)
clusters = dbscan.fit_predict(pca_df)

labels = dbscan.labels_

print("Cluster assignments:\n", labels)

plt.scatter(pca_df.iloc[:,0], pca_df.iloc[:,1], c=clusters)
plt.xlabel('GDP per capita')
plt.ylabel('Life expectancy')
plt.show()

predictions_db = pd.Series(labels)
predictions_db

unique_labels, counts = np.unique(labels, return_counts=True)
percentages = counts / len(labels) * 100

# Print the value counts and percentages
print("Value counts:")
for i, label in enumerate(unique_labels):
    print(f"Class {label}: {counts[i]}")
print("")

print("Percentages:")
for i, label in enumerate(unique_labels):
    print(f"Class {label}: {percentages[i]:.2f}%")

print('Silhouette Score:', silhouette_score(pca_df, predictions_db))

pca_df['Class'] = predictions_db
data = data.drop(columns = ['Class'])
data['Class'] = predictions_db

# Bar plot
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))

plt.subplot(1,2,1)
sns.barplot(x = 'Class', y = 'child_mort', data  = data);
plt.title('child_mort vs Class')

plt.subplot(1,2,2)
sns.barplot(x = 'Class', y = 'income', data  = data);
plt.title('income vs Class')

plt.show()

pca_df.insert(0,column = 'Country', value = data['country'])

pca_df['Class'] = pca_df['Class'].replace({-1: 'Noise', 0: 'Might', 1: 'Yes',2: 'No'})
pca_df.head()